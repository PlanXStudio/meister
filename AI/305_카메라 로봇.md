# 카메라 로봇
Serbot2에 연결된 CSI 카메라로부터 영상 데이터를 OpenCV로 읽어 로봇 GUI에 표시해 봅니다.

## 카메라 데이터 변환 과정
카메라가 빛을 디지털 데이터로 변환하는 과정은 정교한 기술의 조합입니다. 빛이 디지털 이미지로 변환되는 과정을 단계별로 살펴보겠습니다.

1. 빛의 포착  
렌즈를 통해 들어온 빛은 이미지 센서에 도달합니다. 이미지 센서는 수백만 개의 작은 픽셀로 이루어져 있으며, 각 픽셀은 빛을 전기 신호로 변환하는 역할을 합니다.
빛의 양에 따라 각 픽셀에서 생성되는 전기 신호의 강도가 달라집니다.

2. 아날로그 신호 생성
각 픽셀에서 생성된 전기 신호는 아날로그 형태입니다. 즉, 연속적인 값을 가지는 신호입니다.

3. 아날로그-디지털 변환
아날로그 신호는 디지털 데이터로 변환되어야 컴퓨터에서 처리할 수 있습니다. 이 과정을 아날로그-디지털 변환 (ADC) 이라고 합니다.
ADC는 아날로그 신호를 일정한 간격으로 샘플링하고, 각 샘플을 디지털 값으로 변환합니다.

4. 디지털 이미지 생성
디지털 값은 각 픽셀의 밝기와 색상 정보를 나타냅니다. 이러한 디지털 값들이 모여 디지털 이미지를 형성합니다.

5. 이미지 처리  
디지털 이미지는 이미지 처리 과정을 거쳐 화질을 개선하고, 노이즈를 제거하고, 색상을 보정합니다.
이미지 처리 과정은 카메라 내부의 이미지 프로세서 또는 컴퓨터에서 수행될 수 있습니다.

6. 저장 및 출력  
최종적으로 처리된 디지털 이미지는 메모리 카드 또는 컴퓨터에 저장됩니다.
저장된 이미지는 컴퓨터 화면, 스마트폰, 또는 프린터를 통해 볼 수 있습니다.
이미지 센서의 종류:

이미지 센서에는 CCD (Charge-Coupled Device)와 CMOS (Complementary Metal-Oxide-Semiconductor) 두 가지 주요 유형이 있습니다.
CCD는 높은 화질을 제공하지만, CMOS에 비해 전력 소비가 많고 가격이 비쌉니다.
CMOS는 CCD에 비해 전력 소비가 적고 가격이 저렴하며, 최근 기술 발전으로 화질도 CCD에 근접하고 있습니다. 대부분의 스마트폰과 디지털 카메라에는 CMOS 이미지 센서가 사용됩니다.

## OpenCV 라이브러리
OpenCV는 이미지와 비디오를 처리하고 분석하는 데 사용되는 무료 컴퓨터 비전 라이브러리입니다. Windows, Linux, macOS, Android, iOS 등 다양한 운영체제와 C++, Python, Java, MATLAB 등 여러 프로그래밍 언어를 지원합니다. 이미지 처리, 객체 탐지, 얼굴 인식, 증강 현실 등 폭넓은 기능을 제공하며, 머신 러닝 알고리즘을 활용하여 이미지 분류, 객체 추적 등 고급 기능도 구현할 수 있습니다. CUDA, OpenCL 등을 통해 GPU 가속을 지원하여 처리 속도를 향상시킬 수도 있습니다.

주요 기능은 다음과 같습니다.
- 이미지/비디오 처리: 이미지/비디오 읽기 및 쓰기, 색상 공간 변환, 필터링, 기하학적 변환 등 다양한 이미지 처리 기능 제공
- 객체 탐지: Haar Cascades, HOG + SVM 등의 알고리즘을 사용하여 이미지에서 특정 객체 탐지
- 얼굴 인식: Eigenfaces, Fisherfaces, LBPH 등의 알고리즘을 사용하여 얼굴을 인식하고 특징 추출
- 특징점 추출 및 매칭: SIFT, SURF, ORB 등의 알고리즘을 사용하여 이미지에서 특징점을 추출하고, 다른 이미지의 특징점과 매칭하여 객체를 추적하거나 이미지 정합
- 카메라 캘리브레이션: 카메라의 왜곡을 보정하고 3차원 정보 추출
- 증강 현실: 마커 기반 증강 현실, 마커리스 증강 현실 등 다양한 증강 현실 기술 구현

### GStreamer 기반 OpenCV
GStreamer는 다양한 소스 지원, 하드웨어 가속, 유연한 파이프라인 구축, 낮은 지연 시간 처리를 통해 실시간 비디오 처리 애플리케이션에 적합한 강력한 멀티미디어 프레임워크입니다.  
OpenCV에서 GStreamer를 사용하면 카메라, 네트워크 스트림, 파일 등 다양한 소스에서 비디오를 가져오고 처리할 수 있습니다. GStreamer는 강력한 파이프라인 기반 멀티미디어 프레임워크로, OpenCV와 함께 사용하면 비디오 처리 기능을 확장하고 유연성을 높일 수 있습니다.  

OpenCV에서 GStreamer를 사용하려면 GStreamer를 설치하고 OpenCV를 GStreamer 지원으로 빌드해야 하는데, Serbot2에는 이밎 적용되어 있습니다. 따라서 cv2.VideoCapture() 함수에서 GStreamer 파이프라인을 지정하면 카메라 데이터를 가져올 수 있습니다.

Serbot2 카메라용 GStreamer 파이프라인은 다음과 같습니다.

```python
gstreamer_cmd = lambda cam_with=1280, cam_height=720, win_with=1280, win_height=720, rate=60, flip=2 : ('nvarguscamerasrc ! '
    'video/x-raw(memory:NVMM), '
    'width={0}, height={1}, '
    'format=NV12, framerate={2}/1 ! '
    'nvvidconv flip-method={3} ! '
    'video/x-raw, width={4}, height={5}, '
    'format=BGRx ! '
    'videoconvert ! appsink').format(cam_with, cam_height, rate, flip, win_with, win_height)
```
GStreamer 파이프라인으로 VideoCapture 객체를 생성하는 방법은 다음과 같습니다.
```python
cam = cv2.VideoCapture(cam_cmd(), cv2.CAP_GSTREAMER)
```

## 카메라 GUI 구현
OpenCV로 읽은 카메라 데이터를 로봇 제어용 GUI 화면에 함께 출력할 때, GUI와 카메라 데이터 읽기가 동시에 수행되어야 하므로 카메라 데이터 처리는 파이썬 스레드 또는 QTimer 중 하나를 이용합니다.

### OpenCV 데이터를 QLabel에 표시
이미지 데이터를 이용해 QImage 객체를 만든 후 이를 QPixmap.formImage()로 변환하면 QLable.setPixmap()으로 레이블에 출력할 수 있습니다.

```python
ret, frame = cam.read()
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) 
h,w,c = frame.shape
pixmap = QPixmap.fromImage(QImage(frame.data, w, h, w * c, QImage.Format_RGB888))
self.lblFrame.setPixmap(pixmap)
```

### 스레드 버전 
스레드를 적용한 버전은 다음과 같습니다.

```python
import cv2
import sys
from threading import Thread

from PySide6.QtWidgets import QApplication, QMainWindow
from PySide6.QtWidgets import QLabel, QPushButton
from PySide6.QtCore import QCoreApplication
from PySide6.QtGui import QImage, QPixmap, QFont

class CamUi(QMainWindow):
    def __init__(self):
        super().__init__()
        
        cam_cmd = lambda cam_with=1280, cam_height=720, win_with=1280, win_height=720, rate=60, flip=2 : ('nvarguscamerasrc ! '
            'video/x-raw(memory:NVMM), '
            'width={0}, height={1}, '
            'format=NV12, framerate={2}/1 ! '
            'nvvidconv flip-method={3} ! '
            'video/x-raw, width={4}, height={5}, '
            'format=BGRx ! '
            'videoconvert ! appsink').format(cam_with, cam_height, rate, flip, win_with, win_height)

        self.cam = cv2.VideoCapture(cam_cmd(), cv2.CAP_GSTREAMER)

        self.frame = QLabel(self)
        self.frame.resize(1280, 720)

        self.pbExit = QPushButton('Exit', self)
        self.pbExit.resize(120, 60)
        self.pbExit.setFont(QFont('', 50))
        self.pbExit.clicked.connect(self.onExit)

        self._is_run = True
        self.frameThread = Thread(target=self.__onFrame)
        self.frameThread.daemon = True
        self.frameThread.start()

    def __del__(self):
        onExit()

    def onExit(self):
        self._is_run = False
        self.frameThread.join()
        self.cam.release()
        QCoreApplication.instance().quit()

    def onFrame(self):
        ret, frame = self.cam.read()
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) 
        h,w,c = frame.shape
        pixmap = QPixmap.fromImage(QImage(frame.data, w, h, w * c, QImage.Format_RGB888))
        self.frame.setPixmap(pixmap)

    def __onFrame(self):
        while self._is_run:
            self.onFrame()

if __name__ == '__main__':
    app = QApplication(sys.argv)
    win = CamUi()
    win.showFullScreen()
    sys.exit(app.exec_())
```

### QTimer 버전
QTimer 적용 버전입니다.

```python
import cv2
import sys
from PySide6.QtWidgets import QApplication, QMainWindow
from PySide6.QtWidgets import QLabel, QPushButton
from PySide6.QtCore import QCoreApplication
from PySide6.QtGui import QImage, QPixmap, QFont
from PySide6.QtCore import QTimer

class CamUi(QMainWindow):
    def __init__(self):
        super().__init__()
        
        cam_cmd = lambda cam_with=1280, cam_height=720, win_with=1280, win_height=720, rate=60, flip=2 : ('nvarguscamerasrc ! '
            'video/x-raw(memory:NVMM), '
            'width={0}, height={1}, '
            'format=NV12, framerate={2}/1 ! '
            'nvvidconv flip-method={3} ! '
            'video/x-raw, width={4}, height={5}, '
            'format=BGRx ! '
            'videoconvert ! appsink').format(cam_with, cam_height, rate, flip, win_with, win_height)

        self.cam = cv2.VideoCapture(cam_cmd(), cv2.CAP_GSTREAMER)

        self.frame = QLabel(self)
        self.frame.resize(1280, 720)

        self.pbExit = QPushButton('Exit', self)
        self.pbExit.resize(120, 60)
        self.pbExit.setFont(QFont('', 50))
        self.pbExit.clicked.connect(self.onExit)

        self.capTimer = QTimer()
        self.capTimer.setInterval(10)
        self.capTimer.timeout.connect(self.onFrame)
        self.capTimer.start()

    def __del__(self):
        if self.capTimer.isActive():
            self.capTimer.stop()

    def onExit(self):
        self.capTimer.stop()
        self.cam.release()
        QCoreApplication.instance().quit()

    def onFrame(self):
        ret, frame = self.cam.read()
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) 
        h,w,c = frame.shape
        pixmap = QPixmap.fromImage(QImage(frame.data, w, h, w * c, QImage.Format_RGB888))
        self.frame.setPixmap(pixmap)

if __name__ == '__main__':
    app = QApplication(sys.argv)
    win = CamUi()
    win.showFullScreen()
    sys.exit(app.exec_())
```
