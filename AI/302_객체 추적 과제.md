# 딥러닝 기반 객체(사람) 추적하기
MS에서 제공하는 코코 데이터셋으로 학습한 딥러닝 기반 실시간 객체 탐지 모델인 Yolo V4 Tiny 모델(이하 Yolo 모델)이 SerBot2에 사전 설치되어 있음

## Yolo 텐서RT 최적화 모델
NVIDIA의 GPU가 내장되어 있고, CUDA가 설치되어 있다면 더 적은 메모리 사용 및 성능 향상을 위해 모델을 텐서RT로 최적화

다음과 같이 Yolo의 텐서RT 최적화 모델을 SerBot2에 설치  
1. Yolo의 텐서RT 최적화 모델 다운로드
   > [layer.zip](https://github.com/user-attachments/files/16257332/layer.zip)
2. 다운받은 layer.zip 압축 해제
   - libyolo_layer.so, yolov4-tiny.trt
4. VSCode를 SerBot2에 원격 연결한 후 libyolo_layer.so와 yolov4-tiny.trt를 다음 경로에 다운로드
   > serbot2 > model > yolov4-tiny 
5. pip로 모듈 설치
```python
pip install numpy==1.23.1 onnx-graphsurgeon
```

## 객체 탐지
Camera 객체로 수신간 이미지 데이터를 Object_Follow 객체에 전달하면 객체 탐지 결과 반환
Object_Follow는 이미지를 Yolo 모델에 전달해 객체를 탐지하며, 코코 데이터셋의 index 번호 0번은 사람.  

해당 객체가 탐지되지 않으면 결과는 None, 탐지되면 경계 박스를 기준으로 딕셔너리 데이터
- x: 경계 박스 중심점 기준 X 좌표 (-1.00 ~ 1.00)
- y: 경계 박스 중심점 기준 Y 좌표 (-1.00 ~ 1.00)
- size_rate: 경계 박스 크기 (0.01 ~ 1.00) 

```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera

cam = Camera()
of = Object_Follow(cam)

def setup():
    of.load_model()

def loop():
    ret = of.detect(index=0)
    print(ret)


def cleanup(*args):
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

## [과제] 사람 추적하기
다음과 같이 사람을 따라다니는 로봇 구현

1. 카메라와 Yolo 모델을 이용해 사람 탐지
2. 사람이 탐지되면 'x'값을 이용해 위치(좌/우/중앙) 추정, 'size_rate'값으로 거리(가깝다/적당/멀다 등) 추정
3. 거리가 너무 가까우면 뒤로 물러나고, 멀먼 앞으로 다가감
4. 사람이 좌/우로 이동하면 로봇도 함께 좌/우로 이동함 

### 객체 탐지 테스트
로봇이 움직이지 않도록 적당한 거치대 위에 올려 놓고 객체 탐지 결과 확인
1. 사람은 로봇과 1.5m (정적 거리) 떨어진 곳에서 로봇의 카메라 중앙에 위치
2. 앞으로 최대 1m까지 이동. 뒤로 최대 2m까지 이동하면서 'size_rate' 값 변화 확인
3. 1m, 1.5m, 2m 거리에서 좌/우로 이동하면서 'x' 값 변화 확인 

### 템플릿 코드  
```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera
from serbot2.LiDAR import Rplidar
from serbot2.driving import Driving

cam = Camera()
of = Object_Follow(cam)
lidar = Rplidar()
bot = Driving()

def setup():
    of.load_model()
    lidar.startMotor()
    
def loop():
    ret = of.detect(index=0)
    if ret:
        pass
        """TODO 
        1. ret['x']와 ret['size_rate']로 위치(좌/우/중앙) 및 거리 추정 
        2. bot의 forward(), backward(), steering을 이용해 이동
        """

def cleanup(*args):
    lidar.stopMotor()
    bot.stop()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

### 코드 수정  
다음 코드는 미완성으로 steering 값 할당과 ret['x']에 대한 조건을 조정할 필요가 있음.  

```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera
from serbot2.LiDAR import Rplidar
from serbot2.driving import Driving

cam = Camera()
of = Object_Follow(cam)
lidar = Rplidar()
bot = Driving()

def setup():
    of.load_model()
    lidar.startMotor()
    
def loop():
    ret = of.detect(index=0)
    print(ret)
    
    if ret:
        t_steering = ret['x'] * 0.35
        bot.steering = 1.0 if t_steering > 1.0 else -1.0 if t_steering < -1.0 else t_steering
        
        if ret['size_rate'] < 0.3:
            bot.forward(30)
        elif ret['size_rate'] < 0.6:
            bot.backward(30)
        else:
            bot.stop()
    else:
        bot.stop()
                    
def cleanup(*args):
    lidar.stopMotor()
    bot.stop()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

### [심화] 거리 추정을 'size_rate' 대신 라이다로 변경
1. 'x', 'y' 값을 참조해 각도 계산 및 라이다로 사람까지의 거리 확인
2. 거리에 따라 로봇 제어
