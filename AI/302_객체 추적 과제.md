# 딥러닝 기반 객체(사람) 추적하기
MS에서 제공하는 코코 데이터셋으로 학습한 딥러닝 기반 실시간 객체 탐지 모델인 Yolo V4 Tiny 모델(이하 Yolo 모델)이 SerBot2에 사전 설치되어 있음

## YOLO 모델
YOLO는 실시간 객체 탐지(Object Detection)를 위한 딥러닝 모델로, 이미지를 한 번만 보고 객체의 종류와 위치를 동시에 예측하는 특징을 가짐

### 특징
- 빠른 속도: 기존의 2단계 객체 탐지 모델과 달리 1단계로 처리하여 실시간 객체 탐지에 적합
- 높은 정확도: 지속적인 버전 업데이트를 통해 높은 정확도 달성
- 다양한 활용: 자율주행, 로봇, 보안 시스템 등 다양한 분야에서 활용

### 동작 원리
- 이미지 분할: 입력 이미지를 SxS 크기의 그리드 셀로 나눔
- 특징 추출: 각 그리드 셀마다 CNN(Convolutional Neural Network)을 통해 특징 추출
- 객체 예측: 각 그리드 셀에서 객체의 존재 여부, 종류, 위치(바운딩 박스) 예측
- 결과 필터링: Non-Maximum Suppression(NMS) 기법을 통해 중복된 예측 결과를 제거하고 최종 결과 출력

### 장점
- 실시간 처리: 빠른 속도로 객체 탐지가 가능하여 실시간 애플리케이션에 적합
- 단순한 구조: 단일 네트워크로 구성되어 있어 학습 및 구현이 용이
- 높은 일반화 성능: 다양한 객체 탐지 문제에 적용 가능

### 한계점
- 작은 객체 탐지 어려움: 작은 객체에 대한 탐지 성능이 상대적으로 낮을 수 있음
- 새로운 객체 탐지 어려움: 학습 데이터에 없는 새로운 객체를 탐지하는 데 어려움이 있을 수 있음

### YOLO의 발전
YOLO는 지속적인 연구 개발을 통해 성능이 향상되고 있으며, 다양한 버전(YOLOv1, YOLOv2, YOLOv3, YOLOv4, YOLOv5, YOLOv7, YOLOv8 등) 발표  
최신 버전에서는 더욱 빠르고 정확한 객체 탐지가 가능하며, 다양한 기능들이 추가되고 있음

### YOLO 모델을 텐서RT로 최적
NVIDIA의 GPU가 내장되어 있고, CUDA가 설치되어 있다면 더 적은 메모리 사용 및 성능 향상을 위해 모델을 텐서RT로 최적화

다음과 같이 Yolo의 텐서RT 최적화 모델을 SerBot2에 설치  
1. Yolo의 텐서RT 최적화 모델 다운로드
   > [layer.zip](https://github.com/user-attachments/files/16257332/layer.zip)
2. 다운받은 layer.zip 압축 해제
   - libyolo_layer.so, yolov4-tiny.trt
4. VSCode를 SerBot2에 원격 연결한 후 libyolo_layer.so와 yolov4-tiny.trt를 다음 경로에 다운로드
   > serbot2 > model > yolov4-tiny 
5. pip로 모듈 설치 (pycuda 설치에 몇 분이 소요될 수 있음)
```python
pip install numpy==1.23.1 pycuda onnx-graphsurgeon 
```

## 객체 탐지
Camera 객체로 수신간 이미지 데이터를 Object_Follow 객체에 전달하면 객체 탐지 결과 반환
Object_Follow는 이미지를 Yolo 모델에 전달해 객체를 탐지하며, 코코 데이터셋의 index 번호 0번은 사람.  

### 카메라 각도 조절
로봇을 바닦에 놓은 상태에서 카메라 프리뷰 화면을 보면서 카메라 각도 조절

```python
import sys 
import signal

from serbot2.AI import Camera

cam = Camera()

def setup():
    pass

def loop():
    cam.show()

def cleanup(*args):
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

카메라 프리뷰는 윈도우 창에 표시되므로 반드시 터미널창에서 DISPLAY 값과 함께 실행해야 함.
```sh
DISPLAY=:0 python3 person_tracking.py
```

### 객체 탐지 결과에서 방향과 거리 예상
Camera 객체를 Object_Follow의 인자로 전달해 Object_Follow 객체를 만든 후 load_model()을 호출하면 텐서RT로 최적화된 Yolo 모델이 메모리에 로드됨  
이후 detect()를 호출하면 카메라로부터 얻은 이미지 데이터에서 객체 탐지 후 결과 반환

```python
from serbot2.AI import Object_Follow, Camera

cam = Camera()
of = Object_Follow(cam)
of.load_model()

while True:
    ret = of.detect(index=0) # index=0은 Person
    print(ret)
```

객체를 탐지하지 못하면 결과는 None, 탐지하면 경계 박스(Bounding Box)에 대한 딕셔너리 데이터
경계 박스는 찾은 개체를 둘러싼 사각형 테두리
- 'x' 키 값: 경계 박스 중심점 기준 X 좌표 (-1.00 ~ 1.00)
- 'y' 키 값: 경계 박스 중심점 기준 Y 좌표 (-1.00 ~ 1.00)
- 'size_rate' 키 값: 경계 박스 크기 (0.01 ~ 1.00) 

```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera

cam = Camera()
of = Object_Follow(cam)

def setup():
    of.load_model()

def loop():
    cam.show()
    ret = of.detect(index=0)
    if ret:
        estimated_steering = ret['x']
        estimated_distance = ret['size_rate']
        print(estimated_steering, estimated_distance)
    else:
        print("Person not found")
 
def cleanup(*args):
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

### 방향과 거리 최적화

**기준 설정**
사람은 로봇과 1.5m 떨어진 곳에서 로봇의 카메라 중앙에 위치

**estimated_steering 값 최적화**
1m, 1.5m, 2m 거리에서 좌/우로 이동하면서 estimated_steering 값 변화 확인  
estimated_steering이 -1.0에서 1.0이 되도록 ret['x']에 일정값을 곱함  
곱한 값이 클수록 정교함은 떨어지나 방향 전환이 빠름  

```python
estimated_steering = ret['x'] * 1.3 # [주의] 결괏값이 -1.0 미만 또는 1.0 초과일 수 있음
if estimated_steering > 1.0:
    estimated_steering = 1.0  
elif estimated_steering < -1.0:
    estimated_steering = -1.0
```

**estimated_distance 값 최적화**
앞으로 최대 1m까지 이동. 뒤로 최대 2m까지 이동하면서 estimated_distance 값 변화 확인  
estimated_distance이 정수가 되도록 ret['size_rate']에 일정값을 곱한 후 int() 함수로 변환 
```python
estimated_distance = int(ret['size_rate'] * 100)
```

## [과제] 사람 추적하기
다음과 같이 사람을 따라다니는 로봇 구현

1. 카메라와 Yolo 모델을 이용해 사람 탐지
2. 사람이 탐지되면 'x'값을 이용해 조향값(좌/우) 추정, 'size_rate'값으로 거리(가깝다/적당/멀다 등) 추정
3. 거리가 너무 가까우면 뒤로 물러나고(backward()), 멀먼 앞으로 다가감(forward())
4. 사람이 좌/우로 이동하면 로봇도 함께 좌/우로 이동함(steering) 

### 템플릿 코드  
```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera
from serbot2.driving import Driving

cam = Camera()
of = Object_Follow(cam)
bot = Driving()

def setup():
    of.load_model()
    
def loop():
    cam.show()
    ret = of.detect(index=0)
    if ret:
        """TODO 
        1. ret['x']와 ret['size_rate']로 조향(좌/우/중앙) 및 거리 추정 
        2. bot의 forward(), backward(), steering을 이용해 이동
        """
    else:
        bot.stop()

def cleanup(*args):
    bot.stop()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

### 참조 코드  
```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera
from serbot2.driving import Driving

cam = Camera()
of = Object_Follow(cam)
bot = Driving()

def setup():
    of.load_model()
    
def loop():
    ret = of.detect(index=0)
    
    if ret:
        estimated_steering = ret['x'] * 1.6
        estimated_distance = int(ret['size_rate'] * 100) 
        print(estimated_steering, estimated_distance)
        
        if estimated_steering > 1.0:
            estimated_steering = 1.0  
        elif estimated_steering < -1.0:
            estimated_steering = -1.0

        bot.steering = estimated_steering
        
        if estimated_distance < 13:
            bot.forward(50)
        elif estimated_distance > 17:
            bot.backward(50)
        else:
            bot.stop()
    else:
        bot.stop()
                    
def cleanup(*args):
    bot.stop()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

### [심화] 거리 추정을 'size_rate' 대신 라이다로 변경
1. 'x', 'y' 값을 참조해 각도 계산 및 라이다로 사람까지의 거리 확인
2. 거리에 따라 로봇 제어
