# 딥러닝 기반 객체(사람) 추적하기
MS에서 제공하는 코코 데이터셋으로 학습한 딥러닝 기반 실시간 객체 탐지 모델인 Yolo V4 Tiny 모델(이하 Yolo 모델)이 SerBot2에 사전 설치되어 있음

## Yolo 텐서RT 최적화 모델
NVIDIA의 GPU가 내장되어 있고, CUDA가 설치되어 있다면 더 적은 메모리 사용 및 성능 향상을 위해 모델을 텐서RT로 최적화

다음과 같이 Yolo의 텐서RT 최적화 모델을 SerBot2에 설치  
1. Yolo의 텐서RT 최적화 모델 다운로드
   > [layer.zip](https://github.com/user-attachments/files/16257332/layer.zip)
2. 다운받은 layer.zip 압축 해제
   - libyolo_layer.so, yolov4-tiny.trt
4. VSCode를 SerBot2에 원격 연결한 후 libyolo_layer.so와 yolov4-tiny.trt를 다음 경로에 다운로드
   > serbot2 > model > yolov4-tiny 
5. pip로 모듈 설치
```python
pip install numpy==1.23.1 onnx-graphsurgeon
```

## 객체 탐지
Camera 객체로 수신간 이미지 데이터를 Object_Follow 객체에 전달하면 객체 탐지 결과 반환
Object_Follow는 이미지를 Yolo 모델에 전달해 객체를 탐지하며, 코코 데이터셋의 index 번호 0번은 사람.  

해당 객체가 탐지되지 않으면 결과는 None, 탐지되면 경계 박스를 기준으로 딕셔너리 데이터
- x: 경계 박스 중심점 기준 X 좌표 (-1.00 ~ 1.00)
- y: 경계 박스 중심점 기준 Y 좌표 (-1.00 ~ 1.00)
- size_rate: 경계 박스 크기 (0.01 ~ 1.00) 

```python
import sys 
import signal

from serbot2.AI import Object_Follow, Camera

cam = Camera()
of = Object_Follow(cam)

def setup():
    of.load_model()

def loop():
    ret = of.detect(index=0)
    print(ret)


def cleanup(*args):
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, cleanup)
    setup()
    while True:
        try:
            loop()
        except:
            break
```

## [과제] 사람 추적하기
다음과 같이 사람을 따라다니는 로봇 구현

1. 카메라와 Yolo 모델을 이용해 사람 탐지
2. 사람이 탐지되면 'x'값을 이용해 위치(좌/우/중앙) 추정, 'size_rate'값으로 거리(가깝다/적당/멀다 등) 추정
3. 거리가 너무 가까우면 뒤로 물러나고, 멀먼 앞으로 다가감
4. 사람이 좌/우로 이동하면 로봇도 함께 좌/우로 이동함 

[심화] 거리 추정을 'size_rate' 대신 라이다로 변경
1. 'x', 'y' 값을 참조해 각도 계산 및 라이다로 사람까지의 거리 확인
2. 거리에 따라 로봇 제어
