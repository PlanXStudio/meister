# 스레드와 멀티프로세스
- 운영체제는 스케쥴링을 통해 여러 프로그램을 동시에 실행할 수 있음
- 초기 스케쥴링의 기본 단위는 프로그램의 상태를 관리하는 프로세스였음
  - 유닉스/리눅스는 fork() API를 통해 현재 프로세스(부모)를 복제한 새로운 프로세스(자식) 생성 지원
  - 멀티 프로세스(Multi-Process) 프로그래밍은 여러 프로세스의 동작을 하나의 코드에 구현
    - 프로세스 복제 방식은 새로운 프로세스에서 더 이상 사용하지 않는 힙이나 전역 변수로 인해 메모리 낭비 문제가 발생
    - 메모리 보호 정책으로 모든 응용 프로그램은 자신의 고유 가상 메모리에서 실행되므로 프로세스 사이 데이터 공유에 운영체제의 도움 필요
- 프로세서 전체를 복제하지 않고, 특정 서브 루틴(함수)만 스케쥴링하는 새로운 방법 고안
  - 프로그램을 실행하면 새로운 부모 프로세스와 메인 스레드(Thread)가 생성됨
    - 전용 함수로 서브 루틴(함수)을 새로운 스레드(작업)로 만들어 여러 스레드를 동시에 실행하는 멀티 스레드(Multi-Thread) 지원
    - 모든 스레드는 개별 스택을 가지며, 힙, 전역 변수, 서브 루틴(함수)과 같은 프로세스 자원을 공유함
      - 공유 자원에 대한 동기화 문제 발생 

## 스레드
- 파이썬 인터프리터는 멀티 스레드 환경에서 객체에 대한 참조 카운터 관리 문제를 해결하기 위해 GIL(Global Interpreter Lock) 사용
  - 파이썬의 메모리 관리 시스템은 객체가 만들어진 후 참조될 때마다(함수 전달을 포함한 변수 대입) 참조 카운터로 이를 관리
    - 인터프리터는 새로운 참조가 이뤄질 때마다 참조 카운터를 증가하고, 참조가 없으면 감소 시킴
    - 더 이상 참조 대상이 없으면(참조 카운터 0) 백드라운드에서 동작하는 스레기 수집기가 해당 객체를 메모리에서 제거
  - 파이썬은 멀티 프로세서 시스템이 흔치 않던 시절에 만들어진 언어이므로 참조 카운트 메커니즘은 스레드 안전성이 없음
    - 다수의 스레드가 동시에 파이썬 바이트 코드를 실행하지 못하게 막는 일종의 뮤텍스(Mutex)로 한 시점에 하나의 스레드에만 공유 자원 접근
    - 객체에 대해 한 번에 하나의 스레드만 허용하는 방법으로 스레드 안전성 확보
- CPU 중심의 알고리즘 병렬 작업에는 적합하지 않으나, 파일이나 통신 입출력(I/O-Bound)을 동시에 수행하는 작업에서는 GIL이 문제되지 않음 
  - CPU에서 하나의 스레드만 실행되고 나머지 스레드는 쉬고 있어도 I/0 작업은 지속될 수 있음

### 메인 스레드
- 파이썬 메인 모듈은 기본적으로 하나의 스레드 환경에서 실행되며,이를 메인 스레드라 함
  - 메인 모듈은 파이썬 인터프리터에 전달되는 첫 번째 스크립트 파일

[my.py]
```python
def main():
    pass:

if __name__ == '__main__':
    main()
```
```sh
python my.py
```

### 작업 스레드
- 메인 스레드와 경쟁하며 동시에 실행되는 스레드를 작업 스레드라 함
- 새로운 작업 스레드는 threading 모듈의 Thread 클래스로 만듦

```python
import time
import threading

def work_thread(symbol):
    pass

def main():
    work = threading.Thread(target=work_thread, args=('o',), daemon=True)
    work.start()
    
    work.join()

if __name__ == '__main__':
    main()  
```
  - target은 작업 스레드로 실행할 함수/메소드 이름
  - args는 튜플 타입으로 작업 스레드에 전달한 인자 지정
  - daemon이 True이면 메인 스레드가 종료할 때 작업 스레드도 함께 종료 

**작업 스레드 종료 확인**
- join()은 작업 스레드가 종료할 때까지 대기
- is_alive()는 대기 없이 작업 스레드의 종료 상태 검사. False이면 종료


```python
def work_thread(symbol, count):
    for _ in range(count):
        print(symbol, end='', flush=True)

def main():
    work = threading.Thread(target=work_thread, args=('#', 10), daemon=True)
    work.start()
    
    while work.is_alive():
        time.sleep(1/1000) 
```

**무한 루프와 안전한 종료**

```python
is_stoped = False

def work_thread(symbol):
    while not is_stoped:
        print(symbol, end='', flush=True)
        time.sleep(20/1000)

def main():
    global is_stoped

    work = threading.Thread(target=work_thread, args=('o',), daemon=True)
    work.start()

    try:
        while True:
            print('x', end='', flush=True)
            time.sleep(20/1000)
    except KeyboardInterrupt:
        is_stoped = True
        work.join()  
```

### 스레드 풀
- concurrent.futures 모듈의 ThreadPoolExecutor 클래스로 최대 스레드 갯수를 지정
- 스레드 풀 객체의 submit()으로 스레드 함수/메소드와 인자 전달
- concurrent.futures의 wait() 함수는 모든 스레드가 종료할 때까지 대기

```python
import concurrent.futures

def work_thread(symbol, count):
    for _ in range(count):
        print(symbol, end='', flush=True)
        time.sleep(10/1000)

def main():
    works = []
        
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:      
        for symbol in ['o', 'x', '#', '-', '@']:
            works.append(executor.submit(work_thread, symbol, 10))
    
    concurrent.futures.wait(works)
```

### 스레드 동기화
- 여러 스레드가 동시에 자원에 접근할 때 발생하는 문제 해결

**경쟁 상태(race condition)**
- 여러 스레드가 동시에 공유 데이터를 읽고 쓸 때 접근 순서에 따라 결과가 달라지는 상태
```python
money = 0

def work_thread(user):
    global money

    print(f"{user}님이 입금을 시작합니다.")
    
    temp_money = money
    temp_money += 1000
    time.sleep(100/1000)
    money = temp_money
        
    print(f"{user}님이 입금을 종료합니다.")

def main():
    works = []
    owner = '최고다'
    
    print(f"X뱅크에 {owner}님의 계좌를 개설 했습니다. 잔고는 {money:,}원 입니다.")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:      
        for user in ['박무식', '이천사', '김말이', '최측근', '찰리윤']:
            works.append(executor.submit(work_thread, user))
    
    concurrent.futures.wait(works)
    
    print(f"X뱅크의 {owner}님 계좌 잔고는 현재 {money:,}원 입니다.")
```

- Lock 객체의 acquire()와 release()로 보호 

```python
import threading

def work_thread(user, lock):
    global money

    print(f"{user}님이 입금을 시작합니다.")
    
    lock.acquire()
    temp_money = money
    temp_money += 1000
    time.sleep(100/1000)
    money = temp_money
    lock.release()
        
    print(f"{user}님이 입금을 종료합니다.")

def main():
    lock = threading.Lock()
    works = []
    owner = '최고다'
    
    print(f"X뱅크에 {owner}님의 계좌를 개설 했습니다. 잔고는 {money:,}원 입니다.")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:      
        for user in ['박무식', '이천사', '김말이', '최측근', '찰리윤']:
            works.append(executor.submit(work_thread, user, lock))
    
    concurrent.futures.wait(works)
    
    print(f"X뱅크의 {owner}님 계좌 잔고는 현재 {money:,}원 입니다.")
```

**교착 상태(deadlock)**
- 다음 조건이 모두 충족되어 여러 스레드가 자원을 사용하지 못하고 대기하는 상태
  - 매 순간 하나의 스레드만 자원 사용(상호 배제)
  - 자원을 가진 스레드는 강제로 자원을 빼앗기지 않음(비선점)
  - 자원을 가진 스레드가 이를 계속 보유하면서 다른 자원을 획득하기 위해 대기(점유와 대기)
  - 점유와 대기 구조가 스레드 사이 원형으로 형성(원형 대기)

```python
def main():
    lock = threading.Lock()
    works = []
    owner = '최고다'
    
    print(f"X뱅크에 {owner}님의 계좌를 개설 했습니다. 잔고는 {money:,}원 입니다.")
    
    lock.acquire()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:      
        for user in ['박무식', '이천사', '김말이', '최측근', '찰리윤']:
            works.append(executor.submit(work_thread, user, lock))
        
        print(">>> 현재 데드락 상황입니다. 5초 후 해제됩니다. ")
        time.sleep(5)
        lock.release()
 
    concurrent.futures.wait(works)
    
    print(f"X뱅크의 {owner}님 계좌 잔고는 현재 {money:,}원 입니다.")
```

- 보호 영역을 명확히 표현하기 위해 with 권장 
```python
def work_thread(user, lock):
    global money

    print(f"{user}님이 입금을 시작합니다.")
    
    with lock:
        temp_money = money
        temp_money += 1000
        time.sleep(100/1000)
        money = temp_money
        
    print(f"{user}님이 입금을 종료합니다.")
```


## 멀티프로세스
- CPU 계산 집약적인(CPU-Bound) 작업에 적합하며, 파이썬 멀티프로세스는 스레드와 사용법이 같아 기존 스레드 코드를 쉽게 프로세스 코드를 바꿀 수 있음
- 전용 메모리 공간에서 실행되므로 프로세스 사이 데이터 공유는 큐와 같은 별도 자원 필요

### 부모 프로세스
- 파이썬 메인 모듈은 기본적으로 하나의 부모 프로세스에서 실행되는 메인 스레드임.

```python
def main():
    pass:

if __name__ == '__main__':
    main()
```

### 자식 프로세스
- 불필요한 프로세스 자원 복재를 최소화기 위해 스레드처럼 서브루틴 위주로 복재한 후 복재하지 않은 메모리 영역에 접근할 때(메모리 접근 예외 발생) 필요한 메모리 영역 복재
- 새로운 자식 프로세스는 multiprocessing 모듈의 Process 클래스로 만듦

```python
import time
import multiprocessing

def child_process(symbol):
    while True:
        print(symbol, end='', flush=True)
        time.sleep(20/1000)

def main():
    child = multiprocessing.Process(target=child_process, args=('o',), daemon=True)
    child.start()

    try:
        while True:
            print('x', end='', flush=True)
            time.sleep(20/1000)
    except KeyboardInterrupt:
       child.terminate()

if __name__ == '__main__':
    main()
```

### 프로세스 사이 데이터 공유
- 프로세스는 스레드와 달리 전역 변수를 공유할 수 없음
- multiprocessing 모듈의 Manager는 멀티프로세스 환경에서 안전하게 데이터를 공유하는 프록시 서버 제공

**Manager 객체**
```python
manager = multiprocessing.Manager()
```

- Manager 객체는 호스팅된 객체와 상호 작용하는 프록시 객체 반환
  - dict(): 딕셔너리 객체 호스팅
  - list(): 리스트 객체 호스팅
  - Value(): int 또는 float와 같은 기본형 객체 호스팅
    - 타입과 초기 값으로 객체를 만든 후 value 속성으로 값 접근 
  - Queue(): 큐 객체 호스팅
    - put()/get()으로 데이터를 넣고 빼내며, empty()/qsize()로 보관된 데이터 갯수 반환

**Queue 프록시 객체로 데이터 공유**
- multiprocessing.cpu_count()은 현재 프로세서(논리 프로세서) 갯수 반환
- multiprocessing.current_process().name은 현재 프로세스 이름 반환

```python
import multiprocessing
import concurrent.futures 
import time

def child_process(start, end, queue):
    total = 0
    for i in range(start, end):
        total += i
    queue.put(total)
    print(multiprocessing.current_process().name, start, end, total)
    
def main():
    manager = multiprocessing.Manager()
    queue = manager.Queue()    
    
    start = 1
    end = 8_000_000
    workers = multiprocessing.cpu_count()
    
    childs = []
    
    t0 = time.time()
    with concurrent.futures.ProcessPoolExecutor(max_workers=workers) as executor:
        step = end // workers + (1 if end % workers else 0)    
        for i in range(start, end, step):
            childs.append(executor.submit(child_process, i, i+step if i+step <= end else end+1, queue))
    concurrent.futures.wait(childs)
    
    total = 0
    while not queue.empty():
        ret = queue.get()
        total += ret

    print(f"time={time.time() - t0:.4f}sec, {total=:,}")

if __name__ == '__main__':
    main()
```
